{
 "metadata": {
  "name": "",
  "signature": "sha256:0dfd87800c5d9d4f8a0a403eb86001ced24f0d4a74500728d19ce35d73f13e16"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "import math as math\n",
      "import argparse\n",
      "import random\n",
      "import glob\n",
      "import cv2\n",
      "# import the necessary packages\n",
      "from DeepDescriptor import DeepDescriptor\n",
      "from searcher import Searcher\n",
      "import argparse\n",
      "import os, random\n",
      "import matplotlib.pyplot as plt \n",
      "from numpy import linalg as LA\n",
      "%matplotlib inline \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "input_size = 64*64;\n",
      "input_dim_used = input_size;\n",
      "model_dict = \"model2/\";\n",
      "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
      "\n",
      "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(model_dict)\n",
      "debug = 1;\n",
      "scale = 1;\n",
      "if debug:\n",
      "    input_dim_used = input_size/scale;\n",
      "else:\n",
      "    input_dim_used = input_size"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model2/\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_path = '../../fashion_train/';\n",
      "filename = model_dict+\"saveImage\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#cd = DeepDescriptor('inception_3a/output');\n",
      "cd = DeepDescriptor('pool1');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def process(imagePath):\n",
      "    image = cv2.imread(imagePath);\n",
      "    replicate = cv2.copyMakeBorder(image,128,128,128,128,cv2.BORDER_REPLICATE);\n",
      "    (h,w) = (replicate.shape[:2]);\n",
      "    (a,b) = math.ceil(-128+h/2),math.ceil(128+h/2);\n",
      "    (c,d) = math.ceil(-128+w/2),math.ceil(128+w/2);\n",
      "    img = replicate[int(a):int(b), int(c):int(d)];\n",
      "    cv2.imwrite(\"tmp.jpg\",img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#unclear why caffee and tensorflow cannot be used together \n",
      "\n",
      "Filelist = glob.iglob(train_path + \"/*.jpg\");\n",
      "def readfileFromdict(Filelist, batch_size = 1):\n",
      "    b = 0;\n",
      "    read_features  =  np.array([], dtype=np.float).reshape(0,input_dim_used)\n",
      "    imageset = [];\n",
      "    for imagePath in Filelist:\n",
      "        # extract the image ID (i.e. the unique filename) from the image\n",
      "        # path and load the image itself\n",
      "        imageID = imagePath[imagePath.rfind(\"/\") + 1:]\n",
      "        imageset.append(imageID);\n",
      "        #print(imagePath);\n",
      "        process(imagePath);\n",
      "        image = cv2.imread(imagePath);\n",
      "        features = cd.describe(imagePath);\n",
      "        features = np.asarray(features.ravel()).reshape(1,-1)[0][:];\n",
      "        features = features[:input_dim_used]\n",
      "        read_features = np.vstack((read_features,features));\n",
      "        if(b == batch_size-1):\n",
      "            break\n",
      "        b = b+1;\n",
      "    return read_features, imageset ;\n",
      "#shape = readfileFromdict(Filelist).shape;\n",
      "#print(shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Filelist_glob = glob.iglob(train_path + \"/*.jpg\");\n",
      "\n",
      "def file_len(Filelist_glob):\n",
      "    flen = 0;\n",
      "    for imagePath in Filelist_glob:\n",
      "      flen = flen + 1;\n",
      "    return flen;\n",
      "flen = file_len(Filelist_glob);\n",
      "print(\"File size =\", flen);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "File size = 101226\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tensorflow as tf\n",
      "\n",
      "learning_rate = 0.001\n",
      "training_epochs = 1\n",
      "batch_size = 16\n",
      "display_step = 100\n",
      "\n",
      "# Network Parameters\n",
      "n_hidden_1 = 512 # 1st layer num features\n",
      "n_hidden_2 = 64 # 2nd layer num features\n",
      "n_input = input_dim_used #\n",
      "\n",
      "# tf Graph input (only pictures)\n",
      "X = tf.placeholder(\"float\", [None, n_input])\n",
      "\n",
      "weights = {\n",
      "    'encoder_h1': tf.Variable(tf.random_normal([n_input, n_hidden_1]), name = \"eh1\"),\n",
      "    'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name = \"eh2\"),\n",
      "    'decoder_h1': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1]), name = \"dh1\"),\n",
      "    'decoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_input]), name = \"dh2\"),\n",
      "}\n",
      "biases = {\n",
      "    'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1]), name = \"eb1\"),\n",
      "    'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2]), name = \"eb2\"),\n",
      "    'decoder_b1': tf.Variable(tf.random_normal([n_hidden_1]), name = \"db2\"),\n",
      "    'decoder_b2': tf.Variable(tf.random_normal([n_input]), name = \"db2\"),\n",
      "}\n",
      "\n",
      "\n",
      "# Building the encoder\n",
      "def encoder(x):\n",
      "    # Encoder Hidden layer with sigmoid activation #1\n",
      "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
      "                                   biases['encoder_b1']))\n",
      "    # Decoder Hidden layer with sigmoid activation #2\n",
      "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
      "                                   biases['encoder_b2']))\n",
      "    return layer_1\n",
      "\n",
      "\n",
      "# Building the decoder\n",
      "def decoder(x):\n",
      "    # Encoder Hidden layer with sigmoid activation #1\n",
      "  #  layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
      "   #                                biases['decoder_b1']))\n",
      "    # Decoder Hidden layer with sigmoid activation #2\n",
      "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h2']),\n",
      "                                   biases['decoder_b2']))\n",
      "    return layer_2\n",
      "\n",
      "# Construct model\n",
      "encoder_op = encoder(X)\n",
      "decoder_op = decoder(encoder_op)\n",
      "\n",
      "# Prediction\n",
      "y_pred = decoder_op\n",
      "# Targets (Labels) are the input data.\n",
      "y_true = X\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Define loss and optimizer, minimize the squared error\n",
      "cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
      "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
      "\n",
      "\n",
      "# In[8]:\n",
      "\n",
      "# Initializing the variables\n",
      "init = tf.global_variables_initializer()\n",
      "saver2 = tf.train.Saver()\n",
      "\n",
      "# Launch the graph\n",
      "with tf.Session() as sess:\n",
      "    sess.run(init)\n",
      "    total_batch = int(flen/batch_size);\n",
      "    print(training_epochs);\n",
      "  \n",
      "    for epoch in range(total_batch):\n",
      "            batch_xs, image =readfileFromdict(Filelist,batch_size)\n",
      "            # Run optimization op (backprop) and cost op (to get loss value)\n",
      "            _, c = sess.run([optimizer, cost], feed_dict={X: np.array(batch_xs)})\n",
      "        # Display logs per epoch step\n",
      "            if epoch % display_step == 0:\n",
      "              print(\"Epoch:\", '%04d' % (epoch+1),\n",
      "                  \"cost=\", \"{:.9f}\".format(c))\n",
      "              save_path = saver2.save(sess, model_dict+\"model1.ckpt\",global_step = epoch)\n",
      "\n",
      "\n",
      "    print(\"Optimization Finished!\")\n",
      "\n",
      "    print(\"Model2 saved in file: %s\" % save_path)\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0001 cost= 0.467953801\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0101 cost= 0.466577649\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0201 cost= 0.390693218\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0301 cost= 0.246634632\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0401 cost= 0.217967436\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0501 cost= 0.204010457\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0601 cost= 0.197939649\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0701 cost= 0.191231802\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0801 cost= 0.186134025\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0901 cost= 0.183808774\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1001 cost= 0.181393147\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1101 cost= 0.179506540\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1201 cost= 0.176861405\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1301 cost= 0.174623519\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1401 cost= 0.172625884\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1501 cost= 0.171304837\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1601 cost= 0.170037866\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1701 cost= 0.169110954\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1801 cost= 0.167867258\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1901 cost= 0.167107403\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2001 cost= 0.165223405\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2101 cost= 0.164711833\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2201 cost= 0.163841337\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2301 cost= 0.162640870\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2401 cost= 0.162310645\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2501 cost= 0.161186308\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2601 cost= 0.159946859\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2701 cost= 0.159167409\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2801 cost= 0.158603042\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2901 cost= 0.158026233\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3001 cost= 0.157474831\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3101 cost= 0.157390416\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3201 cost= 0.156328589\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3301 cost= 0.156115040\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3401 cost= 0.155954853\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3501 cost= 0.156171575\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3601 cost= 0.155801162\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3701 cost= 0.155648306\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3801 cost= 0.155478120\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3901 cost= 0.154963404\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4001 cost= 0.154667556\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4101 cost= 0.154748127\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4201 cost= 0.154613197\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4301 cost= 0.153953061\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4401 cost= 0.153506711\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4501 cost= 0.152736947\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4601 cost= 0.152892098\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4701 cost= 0.152535841\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4801 cost= 0.150897413\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4901 cost= 0.150472358\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5001 cost= 0.150253832\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5101 cost= 0.149494946\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5201 cost= 0.149587974\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5301 cost= 0.149057209\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5401 cost= 0.148021072\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5501 cost= 0.148470521\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5601 cost= 0.148043513\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5701 cost= 0.147739336\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5801 cost= 0.147583917\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5901 cost= 0.147843853\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6001 cost= 0.147305697\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6101 cost= 0.147865847\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6201 cost= 0.147343561\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6301 cost= 0.146867722\n",
        "Optimization Finished!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Model2 saved in file: model2/model1.ckpt-6300\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "error1 = 0;\n",
      "error2 = 0;\n",
      "saver = tf.train.Saver()\n",
      "init = tf.global_variables_initializer()\n",
      "\n",
      "Filelist = glob.iglob(train_path + \"/*.jpg\");\n",
      "\n",
      "sess = tf.Session();\n",
      "  # Restore variables from disk.\n",
      "ckpt = tf.train.get_checkpoint_state(model_dict)\n",
      "if ckpt and ckpt.model_checkpoint_path:\n",
      "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
      "else:\n",
      "    print(\"No model found\")\n",
      "print(\"Model restored.\");\n",
      "#store data in number of batches \n",
      "ntrees = 10;\n",
      "nSamplesPerTree = int(math.floor(flen/ntrees));\n",
      "for nt in xrange(ntrees):\n",
      "  image_idx = open(filename+str(nt), \"w\")\n",
      "  print(\"Inside \", nt, \"tree\");\n",
      "  X_train = np.array([], dtype=np.float).reshape(0,512);\n",
      "  for i in xrange(nSamplesPerTree):\n",
      "      batch = []\n",
      "      if i % 1000 == 1:\n",
      "        print(i);\n",
      "      batch, imagename = readfileFromdict(Filelist);\n",
      "      image_idx.write(\"%s \\n\" % imagename)\n",
      "      batch = np.array(batch);\n",
      "      encode = sess.run(\n",
      "          encoder_op, feed_dict={X: batch})\n",
      "      encode_decode = sess.run(\n",
      "            decoder_op, feed_dict={X: batch})\n",
      "      c = sess.run(cost, feed_dict={X: batch})\n",
      "      if(i <= 80000):\n",
      "            error1 = error1+c;\n",
      "      else:\n",
      "            error2 = error2+c;\n",
      "       # print(encode_decode)\n",
      "      X_train = np.vstack((X_train,encode));\n",
      "  print(X_train.shape)\n",
      "  image_idx.close();\n",
      "  print(\"rms error training/validation\",error1,error2)\n",
      "  print(X_train.shape)\n",
      "  from sklearn.neighbors import LSHForest\n",
      "  import pickle\n",
      "  lshf = LSHForest(n_candidates=50, n_estimators = 10);\n",
      "  lshf.fit(X_train) ;\n",
      "  pickle.dump(lshf,open( model_dict+\"LSFModelsave.p\"+str(nt), \"wb\" ));\n",
      "  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Model restored.\n",
        "Inside  0 tree\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-11-6f82d59beacf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0merror2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m        \u001b[0;31m# print(encode_decode)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mimage_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/bhorkar/.local/lib/python2.7/site-packages/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import the necessary packages\n",
      "from DeepDescriptor import DeepDescriptor\n",
      "from searcher_lsf import Searcher\n",
      "import argparse\n",
      "import cv2\n",
      "import linecache;\n",
      "\n",
      "\n",
      "# load the query image and describe it\n",
      "nQuery_images = 10;\n",
      "Query_list = [];\n",
      "for counter in xrange(nQuery_images):\n",
      "  qfile = random.choice(os.listdir(train_path));\n",
      "  query = (train_path + \"/\" + qfile);\n",
      "  #query = train_path + \"dress__300846758-default__2ce17d5de7e0661e1552838861cf8073__6.4836845397998.45478820854.7946472168409.0.jpg\";\n",
      "  print(query)\n",
      "  Query_list.append(query);\n",
      "print(\"Query images\") \n",
      "plt.figure(figsize=(15,15));\n",
      "lensq = math.ceil(math.sqrt(nQuery_images));\n",
      "qidx = 1;    \n",
      "for ilen in range(len(Query_list)):\n",
      "  query = Query_list[ilen];\n",
      "  img = cv2.imread(query);\n",
      " # print query;\n",
      "  plt.subplot(lensq,lensq,qidx);\n",
      "  plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB));\n",
      "  qidx += 1;\n",
      "  \n",
      "plt.show();        \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ilen in range(len(Query_list)):\n",
      "  query = Query_list[ilen];\n",
      " # print(query)\n",
      "  img = cv2.imread(query);\n",
      "  print(\"Query\") \n",
      "# display the query\n",
      "  plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB));\n",
      "  plt.show();\n",
      "  features = cd.describe(query);\n",
      "  feature = np.reshape(features,(1,input_dim_used));\n",
      "  batch = np.array(feature);\n",
      "  encoded_feature = sess.run(encoder_op, feed_dict={X: batch});\n",
      "\n",
      "  resultsf = {};\n",
      "  for nt in xrange(0,ntrees):\n",
      "    print(\"Inside \", nt, \"tree\");\n",
      "    lshfr = pickle.load( open( model_dict+\"LSFModelsave.p\"+str(nt), \"rb\" ) )\n",
      "    dist,results = lshfr.kneighbors(encoded_feature, n_neighbors=10);\n",
      "    print(dist);\n",
      "    #dist1,results = kdt.query(encoded_feature, k=10);\n",
      "  #print(dist1);\n",
      "    results = results[0];\n",
      "            #  print(\"index in imageset\");\n",
      "    #print(results);\n",
      "    for i in xrange(len(results)):\n",
      "        fileName =linecache.getline(model_dict +'/saveImage'+str(nt),results[i]+1);\n",
      "        fileName = fileName.replace('[','');\n",
      "        fileName = fileName.replace(']','');\n",
      "        fileName = fileName.replace('\\'','');\n",
      "        print(fileName)\n",
      "        if(fileName == ''):\n",
      "            continue;\n",
      "        resultsf[fileName] = dist[0][i];\n",
      "               # open the index file for reading\n",
      "                # return our (limited) results\n",
      "\n",
      "  resultsf = sorted([(v, k) for (k, v) in resultsf.items()])\n",
      "              #print resultsf\n",
      "            \n",
      "\n",
      "# perform the search\n",
      "#  results_pool_2 = searcher.search(encoded_feature)\n",
      "  results_pool_2 = resultsf;\n",
      "#\n",
      "  plt.figure(figsize=(15,15));\n",
      "  lenf = len( results_pool_2);\n",
      "  lensq = math.ceil(math.sqrt(lenf));\n",
      "  resultidx = 1;\n",
      "  #print  results_pool_2\n",
      " # print(\"Similarity\"); \n",
      "# loop over the results\n",
      "  for (score, resultID) in results_pool_2:\n",
      "\t# load the result image and display it\n",
      "    fname = train_path  + resultID;\n",
      "    fname = fname.strip();\n",
      "    result = cv2.imread(fname);\n",
      "   # print(result)\n",
      "    plt.subplot(lensq,lensq,resultidx);\n",
      "    plt.imshow(cv2.cvtColor(result,cv2.COLOR_BGR2RGB));\n",
      "    resultidx += 1;\n",
      "  plt.show();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}